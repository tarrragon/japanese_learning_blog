#!/usr/bin/env python3
# /// script
# dependencies = []
# requires-python = ">=3.10"
# ///

"""
fix-wikilinks.py - ä¿®æ­£ Wikilink æ ¼å¼ç‚ºæ¨™æº– Markdown é€£çµ

é€™å€‹è…³æœ¬æœƒæƒææ‰€æœ‰å¡ç‰‡ï¼Œå°‡ Obsidian/Wikilink æ ¼å¼ [[path|text]] æˆ– [[path]]
è½‰æ›ç‚ºæ¨™æº– Markdown æ ¼å¼ [text](path.md)ï¼Œä¸¦æ­£ç¢ºè¨ˆç®—ç›¸å°è·¯å¾‘ã€‚

ä½¿ç”¨æ–¹å¼ï¼š
    # æª¢æ¸¬å•é¡Œ
    uv run scripts/fix-wikilinks.py --check

    # é è¦½è®Šæ›´
    uv run scripts/fix-wikilinks.py --dry-run

    # åŸ·è¡Œä¿®æ­£
    uv run scripts/fix-wikilinks.py --fix

    # åªä¿®æ­£ç‰¹å®šåˆ†é¡
    uv run scripts/fix-wikilinks.py --fix --category grammar

    # é©—è­‰ä¿®æ­£çµæœ
    uv run scripts/fix-wikilinks.py --verify
"""

import re
import sys
from pathlib import Path
from typing import List, Tuple, Dict
from dataclasses import dataclass


@dataclass
class WikilinkMatch:
    """Wikilink åŒ¹é…çµæœ"""
    original: str      # åŸå§‹æ–‡å­— [[path|text]] æˆ– [[path]]
    path: str          # è·¯å¾‘éƒ¨åˆ†
    text: str          # é¡¯ç¤ºæ–‡å­—
    line_num: int      # è¡Œè™Ÿ
    context: str       # ä¸Šä¸‹æ–‡ï¼ˆå‰å¾Œå„ 20 å­—å…ƒï¼‰


class WikilinkFixer:
    def __init__(self, zettelkasten_root: Path):
        self.root = zettelkasten_root
        self.wikilink_pattern = re.compile(r'\[\[([^\]|]+?)(?:\|([^\]]+?))?\]\]')

    def find_wikilinks_in_file(self, file_path: Path) -> List[WikilinkMatch]:
        """åœ¨æª”æ¡ˆä¸­å°‹æ‰¾æ‰€æœ‰ wikilink"""
        matches = []

        try:
            content = file_path.read_text(encoding='utf-8')
            lines = content.split('\n')

            for line_num, line in enumerate(lines, start=1):
                for match in self.wikilink_pattern.finditer(line):
                    path = match.group(1)
                    text = match.group(2) if match.group(2) else path.split('/')[-1]

                    # æå–ä¸Šä¸‹æ–‡
                    start = max(0, match.start() - 20)
                    end = min(len(line), match.end() + 20)
                    context = line[start:end]

                    matches.append(WikilinkMatch(
                        original=match.group(0),
                        path=path,
                        text=text,
                        line_num=line_num,
                        context=context
                    ))
        except Exception as e:
            print(f"âŒ è®€å–æª”æ¡ˆå¤±æ•— {file_path}: {e}", file=sys.stderr)

        return matches

    def convert_wikilink_to_markdown(self, wikilink: WikilinkMatch, current_file: Path) -> str:
        """å°‡ wikilink è½‰æ›ç‚ºæ¨™æº– Markdown é€£çµ"""
        # è§£æè·¯å¾‘ï¼šcategory/number_name -> category/number_name.md
        path_parts = wikilink.path.split('/')

        if len(path_parts) == 2:
            category, name = path_parts
            # å¦‚æœæ²’æœ‰ .md å¾Œç¶´ï¼ŒåŠ ä¸Šå®ƒ
            if not name.endswith('.md'):
                # æª¢æŸ¥æ˜¯å¦æœ‰ç·¨è™Ÿå‰ç¶´ï¼ˆå¦‚ 001_nameï¼‰
                if '_' in name:
                    # å·²ç¶“æœ‰å®Œæ•´æª”å
                    target_filename = f"{name}.md"
                else:
                    # åªæœ‰åç¨±ï¼Œéœ€è¦æ‰¾åˆ°å°æ‡‰æª”æ¡ˆ
                    # é€™ç¨®æƒ…æ³ä¸‹ï¼Œæˆ‘å€‘ä¿ç•™åŸæ¨£ï¼Œä½†åŠ ä¸Š .md
                    target_filename = f"{name}.md"
            else:
                target_filename = name

            # è¨ˆç®—ç›¸å°è·¯å¾‘
            current_category = current_file.parent.name

            if current_category == category:
                # åŒä¸€åˆ†é¡ï¼Œç›´æ¥ä½¿ç”¨æª”å
                relative_path = target_filename
            else:
                # ä¸åŒåˆ†é¡ï¼Œä½¿ç”¨ ../category/file.md
                relative_path = f"../{category}/{target_filename}"
        else:
            # è·¯å¾‘æ ¼å¼ä¸æ­£ç¢ºï¼Œä¿æŒåŸæ¨£ä½†åŠ ä¸Š .md
            relative_path = f"{wikilink.path}.md"

        # å»ºç«‹æ¨™æº– Markdown é€£çµ
        return f"[{wikilink.text}]({relative_path})"

    def fix_file(self, file_path: Path, dry_run: bool = True) -> Tuple[int, List[str]]:
        """ä¿®æ­£æª”æ¡ˆä¸­çš„ wikilinks"""
        matches = self.find_wikilinks_in_file(file_path)

        if not matches:
            return 0, []

        changes = []
        content = file_path.read_text(encoding='utf-8')
        new_content = content

        # å¾å¾Œå¾€å‰æ›¿æ›ï¼Œé¿å…ä½ç½®åç§»
        for match in sorted(matches, key=lambda m: m.line_num, reverse=True):
            markdown_link = self.convert_wikilink_to_markdown(match, file_path)
            new_content = new_content.replace(match.original, markdown_link, 1)

            changes.append(
                f"  Line {match.line_num}: {match.original} â†’ {markdown_link}"
            )

        if not dry_run:
            file_path.write_text(new_content, encoding='utf-8')

        return len(matches), changes

    def scan_all_files(self, category: str = None) -> Dict[Path, List[WikilinkMatch]]:
        """æƒææ‰€æœ‰æª”æ¡ˆï¼Œæ‰¾å‡ºåŒ…å« wikilinks çš„æª”æ¡ˆ"""
        results = {}

        # æ±ºå®šæƒæç¯„åœ
        if category:
            search_pattern = f"{category}/*.md"
        else:
            search_pattern = "**/*.md"

        for file_path in self.root.glob(search_pattern):
            # è·³é index.md å’Œ _meta ç›®éŒ„
            if file_path.name == 'index.md' or '_meta' in file_path.parts:
                continue

            matches = self.find_wikilinks_in_file(file_path)
            if matches:
                results[file_path] = matches

        return results

    def verify_links(self, category: str = None) -> List[Tuple[Path, str, bool]]:
        """é©—è­‰æ‰€æœ‰é€£çµæ˜¯å¦æœ‰æ•ˆ"""
        issues = []

        # æ¨™æº– Markdown é€£çµæ¨¡å¼
        md_link_pattern = re.compile(r'\[([^\]]+)\]\(([^\)]+)\)')

        if category:
            search_pattern = f"{category}/*.md"
        else:
            search_pattern = "**/*.md"

        for file_path in self.root.glob(search_pattern):
            if file_path.name == 'index.md' or '_meta' in file_path.parts:
                continue

            content = file_path.read_text(encoding='utf-8')

            for match in md_link_pattern.finditer(content):
                link_text = match.group(1)
                link_path = match.group(2)

                # è§£æç›¸å°è·¯å¾‘
                if link_path.startswith('http'):
                    continue  # è·³éå¤–éƒ¨é€£çµ

                # è¨ˆç®—çµ•å°è·¯å¾‘
                if link_path.startswith('../'):
                    target_path = (file_path.parent / link_path).resolve()
                else:
                    target_path = (file_path.parent / link_path).resolve()

                # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
                exists = target_path.exists()
                if not exists:
                    issues.append((file_path, link_path, False))

        return issues


def print_check_results(results: Dict[Path, List[WikilinkMatch]], root: Path):
    """åˆ—å°æª¢æ¸¬çµæœ"""
    total_files = len(results)
    total_links = sum(len(matches) for matches in results.values())

    print(f"ğŸ“Š æƒæçµæœ")
    print(f"  - ç™¼ç¾ {total_files} å€‹æª”æ¡ˆåŒ…å« Wikilink æ ¼å¼")
    print(f"  - ç¸½å…± {total_links} å€‹ Wikilink éœ€è¦ä¿®æ­£")
    print()

    # æŒ‰åˆ†é¡çµ±è¨ˆ
    by_category = {}
    for file_path, matches in results.items():
        category = file_path.parent.name
        by_category[category] = by_category.get(category, 0) + len(matches)

    print("ğŸ“ å„åˆ†é¡çµ±è¨ˆï¼š")
    for category in sorted(by_category.keys()):
        count = by_category[category]
        print(f"  - {category}: {count} å€‹ wikilinks")
    print()

    # é¡¯ç¤ºå‰ 10 å€‹æª”æ¡ˆä½œç‚ºç¯„ä¾‹
    print("ğŸ“„ å‰ 10 å€‹å—å½±éŸ¿çš„æª”æ¡ˆï¼š")
    for i, (file_path, matches) in enumerate(list(results.items())[:10], start=1):
        rel_path = file_path.relative_to(root)
        print(f"  {i}. {rel_path} - {len(matches)} å€‹ wikilinks")
        # é¡¯ç¤ºç¬¬ä¸€å€‹ wikilink ä½œç‚ºç¯„ä¾‹
        if matches:
            print(f"     ç¯„ä¾‹: {matches[0].original}")

    if total_files > 10:
        print(f"  ... é‚„æœ‰ {total_files - 10} å€‹æª”æ¡ˆ")
    print()


def print_dry_run_results(results: Dict[Path, Tuple[int, List[str]]], root: Path):
    """åˆ—å° dry-run çµæœ"""
    total_changes = sum(count for count, _ in results.values())

    print(f"ğŸ” é è¦½ä¿®æ­£çµæœ")
    print(f"  - å°‡ä¿®æ­£ {len(results)} å€‹æª”æ¡ˆ")
    print(f"  - ç¸½å…± {total_changes} å€‹è®Šæ›´")
    print()

    for file_path, (count, changes) in results.items():
        rel_path = file_path.relative_to(root)
        print(f"ğŸ“ {rel_path} ({count} å€‹è®Šæ›´)")
        for change in changes[:3]:  # åªé¡¯ç¤ºå‰ 3 å€‹
            print(change)
        if len(changes) > 3:
            print(f"  ... é‚„æœ‰ {len(changes) - 3} å€‹è®Šæ›´")
        print()


def main():
    import argparse

    parser = argparse.ArgumentParser(
        description='ä¿®æ­£ Wikilink æ ¼å¼ç‚ºæ¨™æº– Markdown é€£çµ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹ï¼š
  # æª¢æ¸¬å•é¡Œ
  uv run scripts/fix-wikilinks.py --check

  # é è¦½è®Šæ›´
  uv run scripts/fix-wikilinks.py --dry-run

  # åŸ·è¡Œä¿®æ­£
  uv run scripts/fix-wikilinks.py --fix

  # åªä¿®æ­£ç‰¹å®šåˆ†é¡
  uv run scripts/fix-wikilinks.py --fix --category grammar

  # é©—è­‰ä¿®æ­£çµæœ
  uv run scripts/fix-wikilinks.py --verify
        """
    )

    parser.add_argument('--check', action='store_true', help='åªæª¢æ¸¬å•é¡Œï¼Œä¸ä¿®æ­£')
    parser.add_argument('--dry-run', action='store_true', help='é è¦½è®Šæ›´ï¼Œä¸å¯¦éš›ä¿®æ”¹æª”æ¡ˆ')
    parser.add_argument('--fix', action='store_true', help='åŸ·è¡Œä¿®æ­£')
    parser.add_argument('--verify', action='store_true', help='é©—è­‰é€£çµæœ‰æ•ˆæ€§')
    parser.add_argument('--category', type=str, help='åªè™•ç†ç‰¹å®šåˆ†é¡')

    args = parser.parse_args()

    # è‡³å°‘è¦é¸ä¸€å€‹æ¨¡å¼
    if not any([args.check, args.dry_run, args.fix, args.verify]):
        parser.print_help()
        sys.exit(1)

    # æ‰¾åˆ° zettelkasten æ ¹ç›®éŒ„
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    zettelkasten_root = project_root / 'zettelkasten'

    if not zettelkasten_root.exists():
        print(f"âŒ æ‰¾ä¸åˆ° zettelkasten ç›®éŒ„: {zettelkasten_root}", file=sys.stderr)
        sys.exit(1)

    fixer = WikilinkFixer(zettelkasten_root)

    # æª¢æ¸¬æ¨¡å¼
    if args.check:
        print("ğŸ” æƒæ Wikilink æ ¼å¼...")
        results = fixer.scan_all_files(args.category)
        print_check_results(results, zettelkasten_root)
        return

    # é è¦½æ¨¡å¼
    if args.dry_run:
        print("ğŸ” é è¦½ä¿®æ­£è®Šæ›´...")
        all_files = fixer.scan_all_files(args.category)
        results = {}

        for file_path in all_files.keys():
            count, changes = fixer.fix_file(file_path, dry_run=True)
            if count > 0:
                results[file_path] = (count, changes)

        print_dry_run_results(results, zettelkasten_root)
        print("ğŸ’¡ ä½¿ç”¨ --fix åŸ·è¡Œå¯¦éš›ä¿®æ­£")
        return

    # ä¿®æ­£æ¨¡å¼
    if args.fix:
        print("âœï¸  é–‹å§‹ä¿®æ­£ Wikilink...")
        all_files = fixer.scan_all_files(args.category)

        total_files = 0
        total_changes = 0

        for file_path in all_files.keys():
            count, changes = fixer.fix_file(file_path, dry_run=False)
            if count > 0:
                rel_path = file_path.relative_to(zettelkasten_root)
                print(f"âœ… {rel_path} - ä¿®æ­£ {count} å€‹é€£çµ")
                total_files += 1
                total_changes += count

        print()
        print(f"ğŸ‰ å®Œæˆï¼ä¿®æ­£äº† {total_files} å€‹æª”æ¡ˆï¼Œå…± {total_changes} å€‹é€£çµ")
        print()
        print("ğŸ’¡ å»ºè­°åŸ·è¡Œ --verify é©—è­‰é€£çµæœ‰æ•ˆæ€§")
        return

    # é©—è­‰æ¨¡å¼
    if args.verify:
        print("ğŸ” é©—è­‰é€£çµæœ‰æ•ˆæ€§...")
        issues = fixer.verify_links(args.category)

        if not issues:
            print("âœ… æ‰€æœ‰é€£çµéƒ½æœ‰æ•ˆï¼")
        else:
            print(f"âš ï¸  ç™¼ç¾ {len(issues)} å€‹å¤±æ•ˆé€£çµï¼š")
            for file_path, link_path, _ in issues[:20]:
                rel_path = file_path.relative_to(zettelkasten_root)
                print(f"  - {rel_path}: {link_path}")

            if len(issues) > 20:
                print(f"  ... é‚„æœ‰ {len(issues) - 20} å€‹å¤±æ•ˆé€£çµ")
        return


if __name__ == '__main__':
    main()
