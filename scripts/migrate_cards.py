#!/usr/bin/env python3
# /// script
# dependencies = ["ruamel.yaml"]
# requires-python = ">=3.10"
# ///

"""
é·ç§»å¡ç‰‡ YAML çµæ§‹åˆ° v1.5.0 æ ¼å¼

ç”¨é€”ï¼šç‚ºå¡ç‰‡ YAML frontmatter æ–°å¢ v1.5.0 æ‰€éœ€çš„æ–°æ¬„ä½
åŸ·è¡Œï¼šuv run scripts/migrate_cards.py [é¸é …]

é¸é …ï¼š
  --dry-run           é è¦½é·ç§»ï¼ˆä¸å¯¦éš›ä¿®æ”¹ï¼‰
  --execute           åŸ·è¡Œé·ç§»
  --category CAT      åªé·ç§»ç‰¹å®šåˆ†é¡
  --limit N           é™åˆ¶é·ç§»æ•¸é‡
  --verbose           é¡¯ç¤ºè©³ç´°è³‡è¨Š
  --format text|json  è¼¸å‡ºæ ¼å¼ï¼ˆé è¨­ textï¼‰

æ–°å¢çš„æ¬„ä½ï¼š
  - version_history: ç‰ˆæœ¬æ­·å²è¿½è¹¤
  - content_verification: å…§å®¹é©—è­‰ç‹€æ…‹
  - link_status: é€£çµçµ±è¨ˆ
"""

import json
import re
import sys
from pathlib import Path
from datetime import date
from collections import defaultdict
from dataclasses import dataclass, field

# å°ˆæ¡ˆæ ¹ç›®éŒ„
PROJECT_ROOT = Path(__file__).parent.parent
ZETTELKASTEN_DIR = PROJECT_ROOT / "zettelkasten"

# ä¸è™•ç†çš„ç›®éŒ„
EXCLUDE_DIRS = {"_meta", ".DS_Store"}

# å¿…è¦çš„å…§å®¹å€å¡Š
REQUIRED_SECTIONS = {
    "japanese": ["## æ—¥æ–‡è§£é‡‹", "## æ—¥æ–‡èª¬æ˜"],
    "english": ["## è‹±æ–‡è§£é‡‹", "## English"],
    "chinese": ["## ä¸­æ–‡è§£é‡‹", "## ä¸­æ–‡"],
}


@dataclass
class MigrationResult:
    """é·ç§»çµæœ"""
    path: str
    category: str
    card_name: str
    status: str = "pending"  # "migrated", "skipped", "error", "dry-run"
    changes: list = field(default_factory=list)
    error_message: str = ""


def parse_yaml_frontmatter(content: str) -> tuple[dict, str, str]:
    """è§£æ YAML frontmatterï¼Œè¿”å› (yaml_dict, yaml_str, body)"""
    yaml_match = re.search(r'^(---\s*\n)(.*?)(\n---\s*\n)', content, re.DOTALL)
    if not yaml_match:
        return {}, "", content

    yaml_str = yaml_match.group(2)
    body = content[yaml_match.end():]
    prefix = yaml_match.group(1)
    suffix = yaml_match.group(3)

    # ç°¡å–®è§£æ YAML
    data = {}
    current_key = None
    current_list = []
    in_list = False

    for line in yaml_str.split("\n"):
        stripped = line.strip()

        if ":" in line and not stripped.startswith("-"):
            # å¦‚æœä¹‹å‰åœ¨åˆ—è¡¨æ¨¡å¼ï¼Œå…ˆä¿å­˜
            if in_list and current_key:
                data[current_key] = current_list
                current_list = []
                in_list = False

            parts = line.split(":", 1)
            key = parts[0].strip()
            value = parts[1].strip() if len(parts) > 1 else ""

            if value.startswith("[") and value.endswith("]"):
                # è¡Œå…§åˆ—è¡¨
                items = value[1:-1].split(",")
                data[key] = [i.strip() for i in items if i.strip()]
            elif value:
                data[key] = value
            else:
                current_key = key
                in_list = True
                current_list = []

        elif stripped.startswith("- ") and in_list:
            current_list.append(stripped[2:].strip())

    if in_list and current_key:
        data[current_key] = current_list

    return data, yaml_str, body


def count_examples(content: str) -> int:
    """è¨ˆç®—ä¾‹å¥æ•¸é‡"""
    pattern = re.findall(r'\*\*ä¾‹å¥\d+\*\*', content)
    if pattern:
        return len(pattern)

    example_section = re.search(r'## ä¾‹å¥(.*?)(?=\n---|\n## |$)', content, re.DOTALL)
    if example_section:
        blocks = re.findall(r'```', example_section.group(1))
        return len(blocks) // 2

    return 0


def count_pending_links(content: str) -> list[str]:
    """æ‰¾å‡ºå¾…å»ºç«‹é€£çµ"""
    pending = []
    patterns = [
        (r'\[([^\]]+)\]\((å¾…å»ºç«‹|ã€å¾…å»ºç«‹ã€‘)\)', 1),  # group 1 æ˜¯æ–‡å­—
        (r'\[å¾…å»ºç«‹[ï¼š:\s]*([^\]]*)\]\([^)]*\)', 1),
    ]

    for pattern, group in patterns:
        matches = re.findall(pattern, content)
        for match in matches:
            text = match if isinstance(match, str) else match[0] if match else ""
            if text and text not in pending:
                pending.append(text)

    return pending


def count_links(content: str) -> tuple[int, int]:
    """è¨ˆç®—é€£çµæ•¸é‡ (outgoing, internal references approximation)"""
    # è¨ˆç®— markdown é€£çµ
    outgoing = len(re.findall(r'\[([^\]]+)\]\(([^)]+\.md)\)', content))

    # incoming éœ€è¦å¾å…¶ä»–æ–‡ä»¶è¨ˆç®—ï¼Œé€™è£¡å…ˆè¨­ç‚º 0
    return outgoing, 0


def check_sections(content: str) -> dict:
    """æª¢æŸ¥ä¸‰èªè§£é‡‹æ˜¯å¦å­˜åœ¨"""
    result = {}
    for lang, headers in REQUIRED_SECTIONS.items():
        result[lang] = any(header in content for header in headers)
    return result


def needs_migration(yaml_data: dict) -> bool:
    """æª¢æŸ¥æ˜¯å¦éœ€è¦é·ç§»"""
    # å¦‚æœå·²ç¶“æœ‰ v1.5.0 çš„æ–°æ¬„ä½ï¼Œå‰‡ä¸éœ€è¦é·ç§»
    if "content_verification" in yaml_data:
        return False
    if "version_history" in yaml_data:
        return False
    if "link_status" in yaml_data:
        return False
    return True


def generate_new_yaml(yaml_data: dict, content: str, file_path: Path) -> str:
    """ç”Ÿæˆæ–°çš„ YAML frontmatter"""
    today = date.today().isoformat()

    # ä¿ç•™åŸæœ‰æ¬„ä½
    lines = []

    # åŸºæœ¬è³‡è¨Š
    for key in ["title", "description", "type", "jlpt"]:
        if key in yaml_data:
            lines.append(f"{key}: {yaml_data[key]}")

    # stage
    stage = yaml_data.get("stage", "pending")
    lines.append(f"stage: {stage}")

    # tags
    if "tags" in yaml_data:
        tags = yaml_data["tags"]
        if isinstance(tags, list):
            lines.append("tags:")
            for tag in tags:
                lines.append(f"  - {tag}")

    # æ—¥æœŸ
    created = yaml_data.get("date", yaml_data.get("created", today))
    updated = yaml_data.get("updated", today)
    lines.append(f"created: {created}")
    lines.append(f"updated: {updated}")

    # æ–°å¢ï¼šversion_history
    lines.append("")
    lines.append("# ç‰ˆæœ¬æ­·å²")
    lines.append("version_history:")
    lines.append(f'  - version: "1.5.0"')
    lines.append(f'    stage: "{stage}"')
    lines.append(f"    date: {today}")

    # æ–°å¢ï¼šcontent_verification
    sections = check_sections(content)
    examples = count_examples(content)
    pending = count_pending_links(content)

    lines.append("")
    lines.append("# å…§å®¹é©—è­‰")
    lines.append("content_verification:")
    lines.append(f"  japanese: {str(sections['japanese']).lower()}")
    lines.append(f"  english: {str(sections['english']).lower()}")
    lines.append(f"  chinese: {str(sections['chinese']).lower()}")
    lines.append(f"  examples_count: {examples}")
    if pending:
        lines.append("  pending_links:")
        for p in pending[:5]:  # æœ€å¤šåˆ— 5 å€‹
            lines.append(f'    - "{p}"')
    else:
        lines.append("  pending_links: []")

    # æ–°å¢ï¼šlink_status
    outgoing, incoming = count_links(content)

    lines.append("")
    lines.append("# é€£çµç‹€æ…‹")
    lines.append("link_status:")
    lines.append(f"  incoming: {incoming}")
    lines.append(f"  outgoing: {outgoing}")
    lines.append(f"  pending: {len(pending)}")
    lines.append(f"  verified_date: {today}")

    # ä¿ç•™ linksï¼ˆå¦‚æœæœ‰ï¼‰
    if "links" in yaml_data:
        lines.append("")
        lines.append("# é€£çµ")
        lines.append("links:")
        if isinstance(yaml_data["links"], dict):
            for k, v in yaml_data["links"].items():
                lines.append(f"  {k}: {v}")

    return "\n".join(lines)


def migrate_card(file_path: Path, execute: bool = False) -> MigrationResult:
    """é·ç§»å–®å€‹å¡ç‰‡"""
    result = MigrationResult(
        path=str(file_path.relative_to(PROJECT_ROOT)),
        category=file_path.parent.name,
        card_name=file_path.stem
    )

    try:
        content = file_path.read_text(encoding="utf-8")
        yaml_data, yaml_str, body = parse_yaml_frontmatter(content)

        if not yaml_data:
            result.status = "skipped"
            result.changes.append("ç„¡ YAML frontmatter")
            return result

        if not needs_migration(yaml_data):
            result.status = "skipped"
            result.changes.append("å·²æ˜¯ v1.5.0 æ ¼å¼")
            return result

        # ç”Ÿæˆæ–° YAML
        new_yaml = generate_new_yaml(yaml_data, content, file_path)

        # è¨˜éŒ„è®Šæ›´
        result.changes.append("æ–°å¢ version_history")
        result.changes.append("æ–°å¢ content_verification")
        result.changes.append("æ–°å¢ link_status")

        if execute:
            # çµ„åˆæ–°å…§å®¹
            new_content = f"---\n{new_yaml}\n---\n{body}"
            file_path.write_text(new_content, encoding="utf-8")
            result.status = "migrated"
        else:
            result.status = "dry-run"

    except Exception as e:
        result.status = "error"
        result.error_message = str(e)

    return result


def scan_and_migrate(category_filter: str = None, limit: int = None, execute: bool = False) -> list[MigrationResult]:
    """æƒæä¸¦é·ç§»å¡ç‰‡"""
    results = []
    count = 0

    if not ZETTELKASTEN_DIR.exists():
        return results

    for category_dir in sorted(ZETTELKASTEN_DIR.iterdir()):
        if not category_dir.is_dir() or category_dir.name in EXCLUDE_DIRS:
            continue

        if category_filter and category_dir.name != category_filter:
            continue

        for card_file in sorted(category_dir.iterdir()):
            if limit and count >= limit:
                break

            if not card_file.is_file() or card_file.suffix != ".md":
                continue
            if card_file.name in ["index.md", "_index.md"]:
                continue

            result = migrate_card(card_file, execute)
            results.append(result)

            if result.status in ["migrated", "dry-run"]:
                count += 1

        if limit and count >= limit:
            break

    return results


def generate_summary(results: list[MigrationResult]) -> dict:
    """ç”Ÿæˆæ‘˜è¦"""
    by_status = defaultdict(int)
    by_category = defaultdict(lambda: {"total": 0, "migrated": 0, "skipped": 0, "error": 0})

    for r in results:
        by_status[r.status] += 1
        by_category[r.category]["total"] += 1
        if r.status in ["migrated", "dry-run"]:
            by_category[r.category]["migrated"] += 1
        elif r.status == "skipped":
            by_category[r.category]["skipped"] += 1
        elif r.status == "error":
            by_category[r.category]["error"] += 1

    return {
        "total": len(results),
        "by_status": dict(by_status),
        "by_category": dict(by_category)
    }


def format_text_output(results: list[MigrationResult], verbose: bool = False):
    """æ ¼å¼åŒ–æ–‡å­—è¼¸å‡º"""
    summary = generate_summary(results)

    print("\n" + "=" * 80)
    print("YAML é·ç§»å ±å‘Š")
    print("=" * 80)

    print(f"\nğŸ“Š æ‘˜è¦çµ±è¨ˆ")
    print(f"  ç¸½å¡ç‰‡æ•¸: {summary['total']}")
    for status, count in summary["by_status"].items():
        icon = "âœ…" if status == "migrated" else "ğŸ”" if status == "dry-run" else "â­ï¸" if status == "skipped" else "âŒ"
        print(f"  {icon} {status}: {count}")

    print(f"\nğŸ“ æŒ‰åˆ†é¡çµ±è¨ˆ:")
    print(f"{'åˆ†é¡':<20} {'ç¸½æ•¸':>6} {'é·ç§»':>6} {'è·³é':>6} {'éŒ¯èª¤':>6}")
    print("-" * 50)
    for cat, stats in sorted(summary["by_category"].items()):
        print(f"{cat:<20} {stats['total']:>6} {stats['migrated']:>6} {stats['skipped']:>6} {stats['error']:>6}")

    if verbose:
        print(f"\nğŸ“ è©³ç´°æ¸…å–®:")
        print("-" * 80)
        for r in results:
            icon = "âœ…" if r.status == "migrated" else "ğŸ”" if r.status == "dry-run" else "â­ï¸" if r.status == "skipped" else "âŒ"
            changes = ", ".join(r.changes) if r.changes else r.error_message or "(ç„¡)"
            print(f"{icon} {r.path}")
            print(f"   è®Šæ›´: {changes}")

    print("\n" + "=" * 80)


def format_json_output(results: list[MigrationResult]):
    """æ ¼å¼åŒ– JSON è¼¸å‡º"""
    summary = generate_summary(results)
    output = {
        "summary": summary,
        "results": [
            {
                "path": r.path,
                "category": r.category,
                "status": r.status,
                "changes": r.changes,
                "error": r.error_message
            }
            for r in results
        ]
    }
    print(json.dumps(output, ensure_ascii=False, indent=2))


def main():
    """ä¸»è¦é‚è¼¯"""
    args = sys.argv[1:]

    # è§£æé¸é …
    execute = "--execute" in args
    dry_run = "--dry-run" in args or not execute
    verbose = "--verbose" in args
    output_format = "json" if "--format" in args and "json" in args else "text"

    category_filter = None
    if "--category" in args:
        idx = args.index("--category")
        if idx + 1 < len(args):
            category_filter = args[idx + 1]

    limit = None
    if "--limit" in args:
        idx = args.index("--limit")
        if idx + 1 < len(args):
            try:
                limit = int(args[idx + 1])
            except ValueError:
                pass

    # åŸ·è¡Œé·ç§»
    if not execute:
        print("\nâš ï¸  Dry-run æ¨¡å¼ï¼šä¸æœƒå¯¦éš›ä¿®æ”¹æª”æ¡ˆ")
        print("   ä½¿ç”¨ --execute ä¾†åŸ·è¡Œå¯¦éš›é·ç§»\n")

    results = scan_and_migrate(category_filter, limit, execute)

    # è¼¸å‡º
    if output_format == "json":
        format_json_output(results)
    else:
        format_text_output(results, verbose)

    # è¿”å›ç‹€æ…‹
    errors = sum(1 for r in results if r.status == "error")
    sys.exit(1 if errors > 0 else 0)


if __name__ == "__main__":
    main()
