#!/usr/bin/env python3
# /// script
# dependencies = []
# requires-python = ">=3.10"
# ///

"""
add-footnote-links.py - è‡ªå‹•è£œå……è…³è¨»ä¸­ç¼ºå°‘çš„å¡ç‰‡é€£çµ

é€™å€‹è…³æœ¬æœƒæƒææ‰€æœ‰å¡ç‰‡çš„è…³è¨»å®šç¾©ï¼Œè­˜åˆ¥ç¼ºå°‘é€£çµçš„æ¦‚å¿µï¼Œä¸¦è‡ªå‹•è£œå……å°æ‡‰çš„å¡ç‰‡é€£çµã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æå–è…³è¨»å®šç¾© [^key]: **æ¦‚å¿µ** - èªªæ˜
2. å¾ç²—é«”é—œéµå­—è­˜åˆ¥æ¦‚å¿µåç¨±
3. ä½¿ç”¨ Glob + YAML æœå°‹å°æ‡‰å¡ç‰‡
4. è£œå……æ¨™æº– Markdown é€£çµï¼šè©³è¦‹ [æ¨™é¡Œ](è·¯å¾‘.md)
5. ç”Ÿæˆç¼ºå¤±å¡ç‰‡å ±å‘Š

ä½¿ç”¨æ–¹å¼ï¼š
    # æª¢æŸ¥ç‹€æ…‹ï¼ˆåªå ±å‘Šï¼‰
    uv run scripts/add-footnote-links.py --check

    # é è¦½è®Šæ›´
    uv run scripts/add-footnote-links.py --dry-run

    # åŸ·è¡Œä¿®æ­£
    uv run scripts/add-footnote-links.py --fix

    # ç”Ÿæˆç¼ºå¤±å¡ç‰‡æ¸…å–®
    uv run scripts/add-footnote-links.py --list-missing

    # è©³ç´°æ¨¡å¼
    uv run scripts/add-footnote-links.py --fix --verbose
"""

import re
import sys
from pathlib import Path
from typing import List, Tuple, Dict, Optional
from dataclasses import dataclass, field


@dataclass
class FootnoteDefinition:
    """è…³è¨»å®šç¾©"""
    key: str              # è…³è¨» keyï¼Œå¦‚ "na-adj"
    content: str          # å®Œæ•´å…§å®¹
    concept: str          # æå–çš„æ¦‚å¿µåç¨±ï¼ˆç²—é«”éƒ¨åˆ†ï¼‰
    has_link: bool        # æ˜¯å¦å·²åŒ…å«é€£çµ
    line_num: int         # è¡Œè™Ÿ
    file_path: Path       # æ‰€å±¬æª”æ¡ˆ


@dataclass
class CardMatch:
    """å¡ç‰‡åŒ¹é…çµæœ"""
    card_path: Path       # å¡ç‰‡è·¯å¾‘
    title: str            # å¡ç‰‡æ¨™é¡Œ
    relevance: int        # ç›¸é—œæ€§è©•åˆ†ï¼ˆ1-10ï¼‰
    reason: str           # åŒ¹é…åŸå› 


@dataclass
class FixResult:
    """ä¿®æ­£çµæœ"""
    file_path: Path
    footnotes_checked: int = 0
    links_added: int = 0
    already_linked: int = 0
    missing_cards: List[str] = field(default_factory=list)
    changes: List[Tuple[int, str, str]] = field(default_factory=list)  # (line, old, new)


class FootnoteExtractor:
    """æå–è…³è¨»å®šç¾©å’Œå¼•ç”¨"""

    # è…³è¨»å®šç¾©ï¼š[^key]: **æ¦‚å¿µ** - èªªæ˜...
    FOOTNOTE_DEF_PATTERN = re.compile(r'^\[(\^[a-zA-Z0-9_-]+)\]:\s*(.+)$')

    # ç²—é«”é—œéµå­—ï¼š**æ–‡å­—**
    BOLD_PATTERN = re.compile(r'\*\*([^*]+?)\*\*')

    # Markdown é€£çµï¼š[text](path)
    LINK_PATTERN = re.compile(r'\[([^\]]+)\]\(([^)]+)\)')

    def extract_footnotes(self, file_path: Path) -> List[FootnoteDefinition]:
        """æå–æª”æ¡ˆä¸­çš„æ‰€æœ‰è…³è¨»å®šç¾©"""
        footnotes = []

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            for i, line in enumerate(lines, 1):
                match = self.FOOTNOTE_DEF_PATTERN.match(line.strip())
                if match:
                    key = match.group(1)
                    content = match.group(2)

                    # æå–æ¦‚å¿µåç¨±ï¼ˆç¬¬ä¸€å€‹ç²—é«”æ–‡å­—ï¼‰
                    bold_match = self.BOLD_PATTERN.search(content)
                    concept = bold_match.group(1) if bold_match else ""

                    # æª¢æŸ¥æ˜¯å¦å·²åŒ…å«å…§éƒ¨é€£çµï¼ˆæ’é™¤å¤–éƒ¨ URLï¼‰
                    has_link = False
                    for link_match in self.LINK_PATTERN.finditer(content):
                        link_target = link_match.group(2)
                        if not link_target.startswith(('http://', 'https://')):
                            has_link = True
                            break

                    footnotes.append(FootnoteDefinition(
                        key=key,
                        content=content,
                        concept=concept,
                        has_link=has_link,
                        line_num=i,
                        file_path=file_path
                    ))

        except Exception as e:
            print(f"âŒ è®€å–æª”æ¡ˆå¤±æ•— {file_path}: {e}", file=sys.stderr)

        return footnotes

    def should_skip_concept(self, concept: str) -> bool:
        """åˆ¤æ–·æ˜¯å¦æ‡‰è·³éé€™å€‹æ¦‚å¿µï¼ˆä¸éœ€è¦é€£çµï¼‰"""
        # è·³éç©ºæ¦‚å¿µ
        if not concept or not concept.strip():
            return True

        # è·³ééçŸ­çš„æ¦‚å¿µï¼ˆå°‘æ–¼ 2 å€‹å­—å…ƒï¼‰
        if len(concept.strip()) < 2:
            return True

        # è·³ééæ–¼é€šç”¨æˆ–ç„¡éœ€é€£çµçš„æ¦‚å¿µ
        skip_patterns = [
            r'^ä¾‹[ï¼š:]',  # ä¾‹ï¼šã€ä¾‹å­
            r'^åƒè€ƒ',     # åƒè€ƒè³‡æ–™
            r'^æ³¨æ„',     # æ³¨æ„äº‹é …
            r'^æç¤º',     # æç¤º
            r'^\d+',      # ç´”æ•¸å­—
            r'^[ï¼ˆ(]',    # ç´”æ‹¬è™Ÿé–‹é ­
        ]

        for pattern in skip_patterns:
            if re.match(pattern, concept):
                return True

        return False


class ConceptMapper:
    """å°‡è…³è¨»æ¦‚å¿µæ˜ å°„åˆ°å¡ç‰‡"""

    def __init__(self, zettelkasten_root: Path):
        self.root = zettelkasten_root

        # Key æ­£è¦åŒ–æ˜ å°„è¡¨
        self.key_normalization = {
            # å‹•è©é¡å‹
            'ichidan': 'ichidan_verb',
            'ichidan-verb': 'ichidan_verb',
            'ru-verb': 'ichidan_verb',
            'ä¸€æ®µå‹•è©': 'ichidan_verb',
            'godan': 'godan_verb',
            'godan-verb': 'godan_verb',
            'u-verb': 'godan_verb',
            'äº”æ®µå‹•è©': 'godan_verb',

            # å½¢å®¹è©
            'na-adj': 'na_adjective',
            'na-adjective': 'na_adjective',
            'i-adj': 'i_adjective',
            'i-adjective': 'i_adjective',

            # å‹•è©å½¢å¼
            'te-form': 'te_form',
            'ta-form': 'ta_form',
            'nai-form': 'nai_form',
            'masu-form': 'masu_form',
            'dict-form': 'dictionary_form',

            # åŠ©è©
            'wo': 'wo',
            'ã‚’': 'wo',
            'ni': 'ni',
            'ã«': 'ni',
            'ga': 'ga',
            'ãŒ': 'ga',
            'wa': 'wa',
            'ã¯': 'wa',
            'de': 'de',
            'ã§': 'de',
        }

    def normalize_concept(self, concept: str) -> str:
        """æ­£è¦åŒ–æ¦‚å¿µåç¨±"""
        # ç§»é™¤æ‹¬è™Ÿå…§å®¹
        concept = re.sub(r'[ï¼ˆ(].*?[ï¼‰)]', '', concept)
        # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
        concept = re.sub(r'[ã€Œã€ã€ã€ï¼š:ã€ï¼Œã€‚]', '', concept)
        # è½‰å°å¯«
        concept_lower = concept.strip().lower()

        # æŸ¥æ‰¾æ˜ å°„è¡¨
        if concept_lower in self.key_normalization:
            return self.key_normalization[concept_lower]

        return concept.strip()

    def find_card_by_concept(self, concept: str, from_file: Path, verbose: bool = False) -> Optional[CardMatch]:
        """æ ¹æ“šæ¦‚å¿µå°‹æ‰¾å°æ‡‰çš„å¡ç‰‡"""
        if not concept:
            return None

        normalized = self.normalize_concept(concept)

        # ç”Ÿæˆæœå°‹é—œéµå­—ï¼ˆç§»é™¤ç©ºæ ¼å’Œç‰¹æ®Šå­—å…ƒï¼‰
        search_keywords = [
            normalized.lower().replace(' ', '_'),
            normalized.lower().replace(' ', '-'),
            concept.lower().replace(' ', '_'),
            concept.lower().replace(' ', '-'),
        ]

        # æ·»åŠ ç‰¹æ®Šé—œéµå­—æ˜ å°„ï¼ˆè™•ç†æ—¥æ–‡æ¦‚å¿µåç¨±ï¼‰
        concept_mapping = {
            'ãªå½¢å®¹è©': ['na', 'adj-na', 'na-adjective'],
            'ã„å½¢å®¹è©': ['i', 'adj-i', 'i-adjective'],
            'ä¸€æ®µå‹•è©': ['ichidan', 'ru-verb'],
            'äº”æ®µå‹•è©': ['godan', 'u-verb'],
            'ä»–å‹•è©': ['transitive'],
            'è‡ªå‹•è©': ['intransitive'],
        }

        for jp_concept, en_keywords in concept_mapping.items():
            if jp_concept in concept:
                search_keywords.extend(en_keywords)

        candidates = []

        # ç­–ç•¥ 1: Glob æœå°‹æª”å
        for keyword in search_keywords:
            if keyword:
                # ç§»é™¤æ—¥æ–‡å­—å…ƒé€²è¡Œæœå°‹ï¼ˆå‡è¨­æª”åæ˜¯ç¾…é¦¬æ‹¼éŸ³ï¼‰
                keyword_clean = re.sub(r'[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¯]', '', keyword).strip('_-')
                if keyword_clean:
                    patterns = [
                        f"**/*{keyword_clean}*.md",
                        f"**/{keyword_clean}.md",
                    ]

                    for pattern in patterns:
                        for card_path in self.root.glob(pattern):
                            if self._is_valid_card(card_path):
                                relevance = self._calculate_relevance(card_path, concept, keyword_clean)
                                candidates.append(CardMatch(
                                    card_path=card_path,
                                    title=self._extract_title(card_path),
                                    relevance=relevance,
                                    reason=f"æª”ååŒ¹é…: {keyword_clean}"
                                ))

        # ç­–ç•¥ 2: æœå°‹ YAML frontmatter
        if not candidates:
            candidates.extend(self._search_by_yaml(concept, normalized))

        # å»é‡ä¸¦æ’åº
        seen = set()
        unique_candidates = []
        for c in candidates:
            if c.card_path not in seen:
                seen.add(c.card_path)
                unique_candidates.append(c)

        # æŒ‰ç›¸é—œæ€§æ’åº
        unique_candidates.sort(key=lambda x: x.relevance, reverse=True)

        if verbose and unique_candidates:
            print(f"  æ‰¾åˆ° {len(unique_candidates)} å€‹å€™é¸å¡ç‰‡ï¼š")
            for c in unique_candidates[:3]:
                print(f"    - {c.card_path.relative_to(self.root)} (è©•åˆ†: {c.relevance})")

        # è¿”å›æœ€ä½³åŒ¹é…
        return unique_candidates[0] if unique_candidates else None

    def _is_valid_card(self, path: Path) -> bool:
        """æª¢æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„å¡ç‰‡æª”æ¡ˆ"""
        # æ’é™¤ç´¢å¼•æª”æ¡ˆ
        if path.name in ['index.md', 'README.md']:
            return False
        # _meta ç›®éŒ„ä¸‹çš„å¡ç‰‡æ˜¯æœ‰æ•ˆçš„ï¼ˆåŒ…å« categories å’Œ tags å®šç¾©ï¼‰
        return True

    def _calculate_relevance(self, card_path: Path, original_concept: str, keyword: str) -> int:
        """è¨ˆç®—å¡ç‰‡ç›¸é—œæ€§è©•åˆ†ï¼ˆ1-10ï¼‰"""
        score = 5  # åŸºç¤åˆ†

        filename = card_path.stem.lower()
        parts = card_path.parts

        # Meta å®šç¾©å¡ç‰‡å„ªå…ˆç´šæœ€é«˜
        if '_meta' in parts and 'categories' in parts:
            score += 8  # Meta categories å¡ç‰‡å¤§å¹…åŠ åˆ†
        elif '_meta' in parts and 'tags' in parts:
            score += 6  # Meta tags å¡ç‰‡åŠ åˆ†

        # æª”ååŒ¹é…åº¦
        filename_tokens = filename.split('_')
        # å®Œå…¨åŒ¹é…ï¼ˆæ’é™¤æ•¸å­—ç·¨è™Ÿï¼‰
        non_numeric_tokens = [t for t in filename_tokens if not t.isdigit()]
        if keyword in non_numeric_tokens:
            score += 5
        # åŒ…å«é—œéµå­—
        elif keyword in filename:
            # ä½†å¦‚æœåªæ˜¯éƒ¨åˆ†åŒ¹é…ï¼Œé™ä½è©•åˆ†
            score += 1

        # ç‰¹å®šé¡åˆ¥åŠ åˆ†
        parent = card_path.parent.name
        if parent in ['grammar', 'particle']:
            score += 2
        elif parent in ['concept', 'contrast']:
            score += 1

        return min(score, 15)

    def _extract_title(self, card_path: Path) -> str:
        """å¾å¡ç‰‡ YAML æå–æ¨™é¡Œ"""
        try:
            with open(card_path, 'r', encoding='utf-8') as f:
                # åªè®€å‰ 30 è¡Œï¼ˆYAML éƒ¨åˆ†ï¼‰
                lines = f.readlines()[:30]

            # ç°¡å–®è§£æ YAMLï¼ˆé¿å…ä¾è³´å¤–éƒ¨åº«ï¼‰
            in_yaml = False
            title = None
            description = None

            for line in lines:
                if line.strip() == '---':
                    if not in_yaml:
                        in_yaml = True
                        continue
                    else:
                        break  # YAML çµæŸ

                if in_yaml:
                    # æå– title
                    title_match = re.match(r'^title:\s*(.+)$', line.strip())
                    if title_match:
                        title = title_match.group(1).strip('"\'')

                    # æå– description
                    desc_match = re.match(r'^description:\s*(.+)$', line.strip())
                    if desc_match:
                        description = desc_match.group(1).strip('"\'')

            # å„ªå…ˆè¿”å› titleï¼Œå…¶æ¬¡ description
            if title:
                return title
            if description:
                return description

        except Exception:
            pass

        # å›é€€åˆ°æª”å
        return card_path.stem.replace('_', ' ').title()

    def _search_by_yaml(self, concept: str, normalized: str) -> List[CardMatch]:
        """é€é YAML frontmatter æœå°‹"""
        candidates = []

        # é€™è£¡å¯ä»¥å¯¦ä½œæ›´é€²éšçš„ YAML æœå°‹
        # ç‚ºäº†æ•ˆç‡è€ƒé‡ï¼Œç›®å‰å…ˆä»¥æª”åæœå°‹ç‚ºä¸»

        return candidates


class LinkBuilder:
    """å»ºç«‹è…³è¨»é€£çµ"""

    def calculate_relative_path(self, from_file: Path, to_file: Path) -> str:
        """è¨ˆç®—ç›¸å°è·¯å¾‘"""
        try:
            # å–å¾—ç›¸å°è·¯å¾‘
            rel_path = to_file.relative_to(from_file.parent)
            return str(rel_path)
        except ValueError:
            # å¦‚æœä¸åœ¨åŒä¸€ç›®éŒ„æ¨¹ï¼Œä½¿ç”¨ ../ å°èˆª
            from_parts = from_file.parent.parts
            to_parts = to_file.parts

            # æ‰¾åˆ°å…±åŒç¥–å…ˆ
            common_length = 0
            for i, (f, t) in enumerate(zip(from_parts, to_parts)):
                if f == t:
                    common_length = i + 1
                else:
                    break

            # è¨ˆç®—éœ€è¦å¤šå°‘å€‹ ../
            up_levels = len(from_parts) - common_length
            down_parts = to_parts[common_length:]

            rel_parts = ['..'] * up_levels + list(down_parts)
            return '/'.join(rel_parts)

    def format_footnote_link(self, definition: str, card_title: str, card_path: str) -> str:
        """æ ¼å¼åŒ–è…³è¨»é€£çµ"""
        # æª¢æŸ¥æ˜¯å¦å·²ç¶“ä»¥å¥è™Ÿçµå°¾
        if definition.rstrip().endswith(('ã€‚', '.')):
            # ç§»é™¤çµå°¾æ¨™é»
            definition = definition.rstrip().rstrip('ã€‚.')

        # æ·»åŠ é€£çµ
        link = f"[{card_title}]({card_path})"
        new_definition = f"{definition}ã€‚è©³è¦‹ {link}"

        return new_definition

    def validate_link(self, link_path: str, base_file: Path) -> bool:
        """é©—è­‰é€£çµæ˜¯å¦æœ‰æ•ˆ"""
        try:
            # è§£æç›¸å°è·¯å¾‘
            target = (base_file.parent / link_path).resolve()
            return target.exists()
        except Exception:
            return False


class FootnoteLinkFixer:
    """ä¸»æ§åˆ¶å™¨"""

    def __init__(self, zettelkasten_root: Path, verbose: bool = False):
        self.root = zettelkasten_root
        self.verbose = verbose
        self.extractor = FootnoteExtractor()
        self.mapper = ConceptMapper(zettelkasten_root)
        self.link_builder = LinkBuilder()

        self.stats = {
            'files_scanned': 0,
            'footnotes_found': 0,
            'footnotes_with_links': 0,
            'footnotes_without_links': 0,
            'links_added': 0,
            'missing_cards': []
        }

    def scan_all_cards(self) -> List[Path]:
        """æƒææ‰€æœ‰å¡ç‰‡"""
        cards = []
        for md_file in self.root.rglob('*.md'):
            # æ’é™¤ç´¢å¼•å’Œ meta
            if md_file.name not in ['index.md', 'README.md']:
                if '_meta' not in md_file.parts:
                    cards.append(md_file)
        return cards

    def check_file(self, file_path: Path) -> FixResult:
        """æª¢æŸ¥å–®ä¸€æª”æ¡ˆ"""
        result = FixResult(file_path=file_path)

        # æå–è…³è¨»
        footnotes = self.extractor.extract_footnotes(file_path)
        result.footnotes_checked = len(footnotes)

        for fn in footnotes:
            self.stats['footnotes_found'] += 1

            if fn.has_link:
                self.stats['footnotes_with_links'] += 1
                result.already_linked += 1
                continue

            self.stats['footnotes_without_links'] += 1

            # è·³éä¸éœ€è¦é€£çµçš„æ¦‚å¿µ
            if self.extractor.should_skip_concept(fn.concept):
                continue

            # å°‹æ‰¾å°æ‡‰å¡ç‰‡
            if self.verbose:
                print(f"  æœå°‹æ¦‚å¿µ: {fn.concept}")

            card_match = self.mapper.find_card_by_concept(fn.concept, file_path, self.verbose)

            if card_match:
                # æ‰¾åˆ°å¡ç‰‡ï¼Œè¨˜éŒ„è®Šæ›´
                rel_path = self.link_builder.calculate_relative_path(file_path, card_match.card_path)
                new_content = self.link_builder.format_footnote_link(
                    fn.content,
                    card_match.title,
                    rel_path
                )
                result.changes.append((fn.line_num, fn.content, new_content))
                result.links_added += 1
            else:
                # æœªæ‰¾åˆ°å¡ç‰‡
                if self.verbose:
                    print(f"  âŒ æœªæ‰¾åˆ°å°æ‡‰å¡ç‰‡: {fn.concept}")
                result.missing_cards.append(fn.concept)

        return result

    def fix_file(self, file_path: Path, dry_run: bool = True) -> FixResult:
        """ä¿®æ­£å–®ä¸€æª”æ¡ˆ"""
        result = self.check_file(file_path)

        if not result.changes:
            return result

        if dry_run:
            return result

        # å¯¦éš›å¯«å…¥è®Šæ›´
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            # æ‡‰ç”¨è®Šæ›´ï¼ˆå¾å¾Œå¾€å‰ï¼Œé¿å…è¡Œè™Ÿåç§»ï¼‰
            for line_num, old_content, new_content in sorted(result.changes, reverse=True):
                # æ‰¾åˆ°å°æ‡‰è¡Œä¸¦æ›¿æ›
                for i in range(line_num - 1, min(line_num + 2, len(lines))):
                    if old_content in lines[i]:
                        lines[i] = lines[i].replace(f': {old_content}', f': {new_content}')
                        break

            # å¯«å›æª”æ¡ˆ
            with open(file_path, 'w', encoding='utf-8') as f:
                f.writelines(lines)

            self.stats['links_added'] += result.links_added

        except Exception as e:
            print(f"âŒ å¯«å…¥æª”æ¡ˆå¤±æ•— {file_path}: {e}", file=sys.stderr)

        return result

    def process_all(self, dry_run: bool = True) -> Dict:
        """è™•ç†æ‰€æœ‰å¡ç‰‡"""
        cards = self.scan_all_cards()
        results = []

        print(f"ğŸ“Š æƒæ {len(cards)} å¼µå¡ç‰‡...")

        for card in cards:
            self.stats['files_scanned'] += 1

            if self.verbose:
                print(f"\nğŸ“„ è™•ç†: {card.relative_to(self.root)}")

            result = self.fix_file(card, dry_run)

            if result.footnotes_checked > 0:
                results.append(result)

                if not self.verbose and result.links_added > 0:
                    status = "ğŸ” é è¦½" if dry_run else "âœ… å·²ä¿®æ­£"
                    print(f"{status}: {card.relative_to(self.root)} (+{result.links_added} é€£çµ)")

            # æ”¶é›†ç¼ºå¤±å¡ç‰‡
            for concept in result.missing_cards:
                if concept not in self.stats['missing_cards']:
                    self.stats['missing_cards'].append(concept)

        return {
            'results': results,
            'stats': self.stats
        }

    def generate_report(self, output_path: Path, missing_cards: List[str]):
        """ç”Ÿæˆç¼ºå¤±å¡ç‰‡å ±å‘Š"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write("# ç¼ºå¤±è…³è¨»å¡ç‰‡å ±å‘Š\n\n")
                f.write(f"ç”Ÿæˆæ™‚é–“ï¼š{Path(__file__).name}\n\n")
                f.write("## çµ±è¨ˆè³‡è¨Š\n\n")
                f.write(f"- ç¼ºå¤±å¡ç‰‡æ¦‚å¿µæ•¸ï¼š{len(missing_cards)}\n\n")
                f.write("## ç¼ºå¤±å¡ç‰‡æ¸…å–®\n\n")

                if missing_cards:
                    for i, concept in enumerate(sorted(set(missing_cards)), 1):
                        f.write(f"{i}. **{concept}**\n")
                else:
                    f.write("*ç„¡ç¼ºå¤±å¡ç‰‡*\n")

            print(f"\nâœ… å ±å‘Šå·²ç”Ÿæˆ: {output_path}")

        except Exception as e:
            print(f"âŒ ç”Ÿæˆå ±å‘Šå¤±æ•—: {e}", file=sys.stderr)


def main():
    import argparse

    parser = argparse.ArgumentParser(description='è‡ªå‹•è£œå……è…³è¨»ä¸­ç¼ºå°‘çš„å¡ç‰‡é€£çµ')
    parser.add_argument('--check', action='store_true', help='åªæª¢æŸ¥ï¼Œä¸ä¿®æ”¹')
    parser.add_argument('--dry-run', action='store_true', help='é è¦½è®Šæ›´ï¼ˆä¸å¯¦éš›å¯«å…¥ï¼‰')
    parser.add_argument('--fix', action='store_true', help='åŸ·è¡Œä¿®æ­£')
    parser.add_argument('--list-missing', action='store_true', help='ç”Ÿæˆç¼ºå¤±å¡ç‰‡æ¸…å–®')
    parser.add_argument('--verbose', '-v', action='store_true', help='è©³ç´°è¼¸å‡º')

    args = parser.parse_args()

    # é è¨­ç‚º check æ¨¡å¼
    if not any([args.check, args.dry_run, args.fix, args.list_missing]):
        args.check = True

    # æ‰¾åˆ°å°ˆæ¡ˆæ ¹ç›®éŒ„
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    zettelkasten_root = project_root / 'zettelkasten'

    if not zettelkasten_root.exists():
        print(f"âŒ æ‰¾ä¸åˆ° zettelkasten ç›®éŒ„: {zettelkasten_root}", file=sys.stderr)
        sys.exit(1)

    # å»ºç«‹ Fixer
    fixer = FootnoteLinkFixer(zettelkasten_root, verbose=args.verbose)

    # åŸ·è¡Œè™•ç†
    dry_run = not args.fix

    if args.check or args.dry_run or args.fix:
        print(f"{'='*60}")
        if args.fix:
            print("ğŸ”§ åŸ·è¡Œæ¨¡å¼ï¼šæ­£å¼ä¿®æ­£")
        elif args.dry_run:
            print("ğŸ” åŸ·è¡Œæ¨¡å¼ï¼šé è¦½è®Šæ›´ï¼ˆDry Runï¼‰")
        else:
            print("ğŸ“Š åŸ·è¡Œæ¨¡å¼ï¼šåƒ…æª¢æŸ¥")
        print(f"{'='*60}\n")

        result = fixer.process_all(dry_run=dry_run)

        # è¼¸å‡ºçµ±è¨ˆ
        stats = result['stats']
        print(f"\n{'='*60}")
        print("ğŸ“Š çµ±è¨ˆè³‡è¨Š")
        print(f"{'='*60}")
        print(f"æƒææª”æ¡ˆæ•¸ï¼š{stats['files_scanned']}")
        print(f"æ‰¾åˆ°è…³è¨»æ•¸ï¼š{stats['footnotes_found']}")
        print(f"  - å·²æœ‰é€£çµï¼š{stats['footnotes_with_links']}")
        print(f"  - ç¼ºå°‘é€£çµï¼š{stats['footnotes_without_links']}")
        if not dry_run:
            print(f"æ–°å¢é€£çµæ•¸ï¼š{stats['links_added']}")
        else:
            total_to_add = sum(r.links_added for r in result['results'])
            print(f"å¯æ–°å¢é€£çµï¼š{total_to_add}")
        print(f"ç¼ºå¤±å¡ç‰‡æ•¸ï¼š{len(stats['missing_cards'])}")
        print(f"{'='*60}\n")

        if stats['missing_cards']:
            print("âš ï¸  ä»¥ä¸‹æ¦‚å¿µç¼ºå°‘å°æ‡‰å¡ç‰‡ï¼š")
            for concept in sorted(set(stats['missing_cards']))[:10]:
                print(f"  - {concept}")
            if len(stats['missing_cards']) > 10:
                print(f"  ... åŠå…¶ä»– {len(stats['missing_cards']) - 10} å€‹")

    if args.list_missing:
        output_path = project_root / 'doc' / 'missing-footnote-cards.md'
        output_path.parent.mkdir(exist_ok=True)

        # å¦‚æœé‚„æ²’åŸ·è¡Œé scanï¼Œå…ˆåŸ·è¡Œ
        if not fixer.stats['files_scanned']:
            result = fixer.process_all(dry_run=True)

        fixer.generate_report(output_path, fixer.stats['missing_cards'])

    if args.fix:
        print("\nâœ… ä¿®æ­£å®Œæˆï¼")
    elif args.dry_run:
        print("\nğŸ’¡ æç¤ºï¼šä½¿ç”¨ --fix åŸ·è¡Œå¯¦éš›ä¿®æ­£")


if __name__ == '__main__':
    main()
